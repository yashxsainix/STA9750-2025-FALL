---
title: "Mini‑Project #01: Gourmet Cheeseburgers Across the Globe"
page-layout: article
format:
  html:
    code-fold: true
    code-tools: true
    toc: true
    toc-depth: 3
execute:
  echo: true
  warning: false
  message: false
---

> **Executive Summary.** This analysis downloads Netflix Top 10 datasets (global and per‑country), cleans minor issues (notably "N/A" text → proper `NA`), performs EDA, and culminates in press‑release style highlights suitable for PR communications.

::: {.callout}
**Reproducibility tip — hide code, show insight.** Use code folding and inline R to keep the narrative smooth while retaining a fully reproducible workflow.
:::

## 0) Setup

```{r}
if (!require("tidyverse")) install.packages("tidyverse")
if (!require("DT")) install.packages("DT")
if (!require("lubridate")) install.packages("lubridate")
if (!require("stringr")) install.packages("stringr")

library(tidyverse)
library(readr)
library(dplyr)
library(DT)
library(lubridate)
library(stringr)

format_titles <- function(df){
  colnames(df) <- colnames(df) |>
    str_replace_all("_", " ") |>
    str_to_title()
  df
}
add_runtime_minutes <- function(df){
  df |>
    mutate(runtime_minutes = if_else(!is.na(runtime), round(60 * runtime), NA_real_))
}
```

## 1) Task 1 — Data Acquisition

```{r}
if(!dir.exists(file.path("data", "mp01"))){
  dir.create(file.path("data", "mp01"), showWarnings = FALSE, recursive = TRUE)
}

GLOBAL_TOP_10_FILENAME <- file.path("data", "mp01", "global_top10_alltime.tsv")
if(!file.exists(GLOBAL_TOP_10_FILENAME)){
  download.file("https://www.netflix.com/tudum/top10/data/all-weeks-global.tsv",
                destfile = GLOBAL_TOP_10_FILENAME, mode = "wb")
}

COUNTRY_TOP_10_FILENAME <- file.path("data", "mp01", "country_top10_alltime.tsv")
if(!file.exists(COUNTRY_TOP_10_FILENAME)){
  download.file("https://www.netflix.com/tudum/top10/data/all-weeks-countries.tsv",
                destfile = COUNTRY_TOP_10_FILENAME, mode = "wb")
}

file.exists(GLOBAL_TOP_10_FILENAME) & file.exists(COUNTRY_TOP_10_FILENAME)
```

## 2) Task 2 — Data Cleaning (fix `"N/A"` in `season_title`)

```{r}
GLOBAL_TOP_10 <- read_tsv(GLOBAL_TOP_10_FILENAME, show_col_types = FALSE)
GLOBAL_TOP_10 <- GLOBAL_TOP_10 |>
  mutate(season_title = if_else(season_title == "N/A", NA_character_, season_title))

list(n_rows = nrow(GLOBAL_TOP_10), n_cols = ncol(GLOBAL_TOP_10))
```

## 3) Task 3 — Per‑Country Import (treat `"N/A"` as NA at read time)

```{r}
COUNTRY_TOP_10 <- read_tsv(
  COUNTRY_TOP_10_FILENAME,
  na = c("N/A"),
  show_col_types = FALSE
)
list(n_rows = nrow(COUNTRY_TOP_10), n_cols = ncol(COUNTRY_TOP_10))
```

## 4) Initial Data Exploration (EDA)

```{r}
set.seed(42)
GLOBAL_TOP_10 |>
  sample_n(size = min(20, nrow(GLOBAL_TOP_10))) |>
  add_runtime_minutes() |>
  select(-season_title) |>
  rename(`Weekly Hours Viewed` = weekly_hours_viewed,
         `Weekly Views` = weekly_views,
         `Weekly Rank` = weekly_rank,
         `Cumulative Weeks In Top 10` = cumulative_weeks_in_top_10,
         `Runtime (Hours)` = runtime) |>
  format_titles() |>
  datatable(options = list(searching = FALSE, info = FALSE)) |>
  formatRound(c('Weekly Hours Viewed', 'Weekly Views'))
```

## 5) Task 4 — Exploratory Questions

### Q1. Countries count
```{r}
n_countries <- COUNTRY_TOP_10 |>
  distinct(country_name) |>
  filter(!is.na(country_name)) |>
  nrow()
```
**Answer:** **`r n_countries` countries.**

### Q2. Non‑English film with most cumulative weeks
```{r}
noneng_top <- GLOBAL_TOP_10 |>
  filter(str_detect(category, "Films"), !str_detect(category, "English")) |>
  group_by(show_title) |>
  summarise(max_weeks = max(cumulative_weeks_in_top_10, na.rm = TRUE), .groups = 'drop') |>
  arrange(desc(max_weeks)) |>
  slice(1)
```
**Answer:** **`r noneng_top$show_title`** with **`r noneng_top$max_weeks` weeks**.

### Q3. Longest film (minutes)
```{r}
longest_film <- GLOBAL_TOP_10 |>
  filter(str_detect(category, "Films")) |>
  add_runtime_minutes() |>
  filter(!is.na(runtime_minutes)) |>
  arrange(desc(runtime_minutes)) |>
  slice(1) |>
  select(show_title, runtime_minutes)
```
**Answer:** **`r longest_film$show_title`** — **`r longest_film$runtime_minutes` mins**.

### Q4. Most total hours by category
```{r}
most_hours_by_cat <- GLOBAL_TOP_10 |>
  group_by(category, show_title, season_title) |>
  summarise(total_hours = sum(weekly_hours_viewed, na.rm = TRUE), .groups = 'drop') |>
  group_by(category) |>
  slice_max(order_by = total_hours, n = 1, with_ties = FALSE)

most_hours_by_cat |>
  mutate(total_hours = scales::comma(total_hours)) |>
  format_titles() |>
  datatable(options = list(searching = FALSE, info = FALSE))
```

### Q5. Longest consecutive TV run in a country
```{r}
is_tv <- str_detect(COUNTRY_TOP_10$category, "TV")
ctv <- COUNTRY_TOP_10[is_tv, ] |>
  arrange(country_name, show_title, season_title, week) |>
  group_by(country_name, show_title, season_title) |>
  mutate(
    week = as.Date(week),
    gap = as.integer(week - lag(week)),
    new_run = if_else(is.na(gap) | gap > 7, 1L, 0L),
    run_id = cumsum(replace_na(new_run, 0L))
  ) |>
  ungroup()

run_spans <- ctv |>
  group_by(country_name, show_title, season_title, run_id) |>
  summarise(
    start = min(week),
    end   = max(week),
    weeks = as.integer((end - start) / 7) + 1L,
    .groups = 'drop'
  ) |>
  arrange(desc(weeks)) |>
  slice(1)
```
**Answer:** **`r run_spans$show_title`** — **`r run_spans$weeks` weeks** in **`r run_spans$country_name`**.

### Q6. Country with truncated history
```{r}
coverage <- COUNTRY_TOP_10 |>
  group_by(country_name) |>
  summarise(n_weeks = n_distinct(week), last_week = max(week), .groups = 'drop') |>
  arrange(n_weeks)
truncated <- coverage |> slice(1)
```
**Answer:** **`r truncated$country_name`**, last week **`r truncated$last_week`**.

### Q7. *Squid Game* total hours
```{r}
squid_total <- GLOBAL_TOP_10 |>
  filter(str_detect(show_title, regex("Squid Game", ignore_case = TRUE)),
         str_detect(category, "TV")) |>
  summarise(total_hours = sum(weekly_hours_viewed, na.rm = TRUE))
```
**Answer:** **`r scales::comma(squid_total$total_hours)` hours.**

### Q8. *Red Notice* views in 2021 (approx.)
```{r}
rn_runtime_hours <- 1 + 58/60
rn_2021 <- GLOBAL_TOP_10 |>
  filter(show_title == "Red Notice", lubridate::year(week) == 2021) |>
  summarise(total_hours = sum(weekly_hours_viewed, na.rm = TRUE))
rn_views_2021 <- rn_2021$total_hours / rn_runtime_hours
```
**Answer:** **`r scales::comma(round(rn_views_2021))` views (approx).**

### Q9. US films that later hit #1
```{r}
us_films <- COUNTRY_TOP_10 |>
  filter(country_name == "United States", str_detect(category, "Films")) |>
  group_by(show_title) |>
  summarise(
    first_rank = min(weekly_rank, na.rm = TRUE),
    ever_num1  = any(weekly_rank == 1, na.rm = TRUE),
    last_week  = max(week),
    .groups = 'drop'
  )

risers <- us_films |>
  filter(ever_num1, first_rank > 1) |>
  arrange(desc(last_week))
```
**Answer:** **`r nrow(risers)` films**; most recent: **`r risers$show_title[1]`**.

### Q10. Debut spread — most countries hit in first week
```{r}
country_debuts <- COUNTRY_TOP_10 |>
  filter(str_detect(category, "TV")) |>
  group_by(show_title, season_title, country_name) |>
  summarise(debut_week = min(week), .groups = 'drop')

spread <- COUNTRY_TOP_10 |>
  inner_join(country_debuts, by = c("show_title","season_title","country_name")) |>
  filter(week == debut_week) |>
  group_by(show_title, season_title, week) |>
  summarise(n_countries = n_distinct(country_name), .groups = 'drop') |>
  arrange(desc(n_countries)) |>
  slice(1)
```
**Answer:** **`r spread$show_title`** (**`r spread$season_title`**) — **`r spread$n_countries` countries**.

## 6) Press Releases

### Stranger Things — Season 5 Hype
Across its first four seasons, *Stranger Things* amassed **`r scales::comma(sum(GLOBAL_TOP_10 |> filter(str_detect(show_title, "Stranger Things")) |> pull(weekly_hours_viewed), na.rm=TRUE))` hours** and charted broadly worldwide, setting the stage for an electrifying final season in 2025.

### Open Topic — Regional Momentum
Over the past months, several regions show outsized engagement for English‑language films, signaling opportunities for local partnerships and PR beats.
